<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>M2 | Nicolas Jouvin</title>
    <link>/tags/m2/</link>
      <atom:link href="/tags/m2/index.xml" rel="self" type="application/rss+xml" />
    <description>M2</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 01 Sep 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>M2</title>
      <link>/tags/m2/</link>
    </image>
    
    <item>
      <title>Data Camp</title>
      <link>/teaching/datacamp/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      <guid>/teaching/datacamp/</guid>
      <description>&lt;h1 id=&#34;description&#34;&gt;Description&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Chargé de cours :&lt;/strong&gt; Nicolas Jouvin&lt;/p&gt;
&lt;p&gt;Ce module a pour but de vous confronter à un problème d&amp;rsquo;apprentissage concret avec toutes les dimensions que cela contient&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;une problématique à laquelle répondre&lt;/li&gt;
&lt;li&gt;Compréhension des données, analyse de l&amp;rsquo;état de l&amp;rsquo;art existant&lt;/li&gt;
&lt;li&gt;construction d&amp;rsquo;un modèle / une pipeline de machine learning&lt;/li&gt;
&lt;li&gt;analyse de ses points forts/faible&lt;/li&gt;
&lt;li&gt;programmer correctement et proprement&lt;/li&gt;
&lt;li&gt;travailler en équipe et maitriser les outils informatiques modernes (git, github)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nous passerons par la plateforme &lt;a href=&#34;https://ramp.studio/&#34;&gt;RAMP.studio&lt;/a&gt; developée par l&amp;rsquo;Université Paris-Saclay.&lt;/p&gt;
&lt;h1 id=&#34;edition-2024-2025&#34;&gt;Edition 2024-2025&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;&#34;&gt;Télécharger les slides de présentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised learning</title>
      <link>/teaching/unsupervised_learning/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate>
      <guid>/teaching/unsupervised_learning/</guid>
      <description>&lt;h1 id=&#34;description&#34;&gt;Description&lt;/h1&gt;
&lt;p&gt;Chargé de cours : Nicolas Jouvin &lt;br&gt;
Horaires : Mercredi 8h30-11h45.&lt;/p&gt;
&lt;h1 id=&#34;slides&#34;&gt;Slides&lt;/h1&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&#34;/docs/unsupervised_learning/slides_cours_unsupervised.pdf&#34;&gt;Up-to-date version of the slides: here&lt;/a&gt; (there will be frequent updates, keep up to date !)&lt;/p&gt;
&lt;h1 id=&#34;news&#34;&gt;News&lt;/h1&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;Exam: mercredi 8 janvier - 8h30-11h30 (Salle à vérifier sur Hyperplanning)&lt;/li&gt;
&lt;li&gt;Devoir maison facultatif : &lt;a href=&#34;/docs/unsupervised_learning/homework/homework_2024.pdf&#34;&gt;télécharger l&amp;rsquo;énoncé ici&lt;/a&gt; (correction le 3 janvier).&lt;/li&gt;
&lt;li&gt;Annales :&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/unsupervised_learning/exam/exam2023-2024.pdf&#34;&gt;Sujet 2023&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/docs/unsupervised_learning/exam/examen2022.pdf&#34;&gt;Sujet 2022&lt;/a&gt; (attention, je n&amp;rsquo;étais pas chargé du cours cette année là)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;outline&#34;&gt;Outline&lt;/h1&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li&gt;Introduction to Bayesian statistics&lt;/li&gt;
&lt;li&gt;Clustering with finite mixture models&lt;/li&gt;
&lt;li&gt;The EM algorithm&lt;/li&gt;
&lt;li&gt;Hidden Markov Models&lt;/li&gt;
&lt;li&gt;Stochastic Block Model and introduction to variational inference&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;séances&#34;&gt;Séances&lt;/h1&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1ère séance :&lt;/strong&gt; 3h class + &lt;a href=&#34;/docs/unsupervised_learning/TD1_bayes/bayesian_exercise_sheet.pdf&#34;&gt;Dowload TD1 exercice sheet&lt;/a&gt; + &lt;a href=&#34;/docs/unsupervised_learning/TD1_bayes/TP_bayes_estimator_enonce.pdf&#34;&gt;Bonus practical session&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Séance 2 &amp;amp; 3:&lt;/strong&gt; Mixture models &amp;amp; Expectation-Maximization algorithm. &lt;a href=&#34;/docs/unsupervised_learning/TD2_GMM/TP_GMM_EM.pdf&#34;&gt;Download the TD2 exercise sheet&lt;/a&gt; + &lt;a href=&#34;/docs/unsupervised_learning/TD2_GMM/correction_live_nicolasjouvin.qmd&#34;&gt;live correction&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;4ème séance :&lt;/strong&gt; Introduction to HMMs + &lt;a href=&#34;/docs/unsupervised_learning/TD_chaine_markov/TP_bonus_chaine_markov_enonce.pdf&#34;&gt;Bonus practical session on discrete Markov chains&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5ème séance:&lt;/strong&gt;  EM algorithm for HMMs (a.k.a. Baum-Welsch) + &lt;a href=&#34;/docs/unsupervised_learning/TD3_HMM/TD_HMM_enonce.pdf&#34;&gt;Practical session on HMMs: EM and Viterbi&lt;/a&gt; + &lt;a href=&#34;/docs/unsupervised_learning/TD3_HMM/live_correction_tp-hmm_njouvin_24-25.qmd&#34;&gt;live_correction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;6ème séance:&lt;/strong&gt;  The stochastic block model &amp;amp; introduction to variational inference&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;corrections&#34;&gt;Corrections&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Séance 2 - chaîne de Markov: &lt;a href=&#34;/docs/unsupervised_learning/TD_chaine_markov/correction_TP_bonus_chaine_markov.pdf&#34;&gt;télécharger le Rmarkdown de correction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Séance 4 : algorithme EM &lt;a href=&#34;/docs/unsupervised_learning/TD_EM/correction_TD_EM.pdf&#34;&gt;télécharger le Rmarkdown de correction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Séance 5 : TP HMM &lt;a href=&#34;/docs/unsupervised_learning/TD3_HMM/TD_HMM_correction_avec_baum_welch.pdf&#34;&gt;télécharger le Rmarkdown de correction&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ressources-en-ligne&#34;&gt;Ressources en ligne&lt;/h1&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www6.inrae.fr/mia-paris/content/download/5122/47577/version/1/file/Part2-Main-MSV2101.pdf&#34;&gt;Stéphane Robin&amp;rsquo;s Lecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sophiedonnet.github.io/LVMclass.html&#34;&gt;Sophie Donnet&amp;rsquo;s Lecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf&#34;&gt;Chistopher M. Bishop&amp;rsquo;s Book&lt;/a&gt; : for this course, relevant chapters are mostly 8, 9 &amp;amp; 10 (chapter 12 on continuous latent variables can be useful as well, the core ideas do not change)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://probml.github.io/pml-book/book1.html&#34;&gt;Kevin P. Murphy&amp;rsquo;s Book&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
